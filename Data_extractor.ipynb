{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.callbacks import CSVLogger\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import savetxt\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def move(validation_data_dir):\n",
    "\n",
    "    gt = pd.read_csv(os.path.join(validation_data_dir, 'ground_truth.txt'),sep = ';', header = None)\n",
    "\n",
    "    for root, dirs, files in os.walk(validation_data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('jpg'):\n",
    "                img_class = gt.loc[gt[0]==file].iloc[0][1]\n",
    "                x = img_class.split(\" \")\n",
    "                x = [i.replace(\":\",\"\") for i in x]\n",
    "                img_class = \"\".join(x)\n",
    "\n",
    "                dir_ = os.path.join(root, img_class)\n",
    "                if not os.path.exists(dir_):\n",
    "                    os.mkdir(dir_)\n",
    "                old, new = os.path.join(root, file), os.path.join(dir_, file)\n",
    "                shutil.move(old, new)\n",
    "    print(\"done\")\n",
    "    \n",
    "#move(validation_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_dir = 'data/sc5-test'\n",
    "train_data_dir = 'data/sc5'\n",
    "val = sorted([i for i in os.listdir(validation_data_dir) if os.path.isdir(os.path.join(os.getcwd(),os.path.join(validation_data_dir,i)))])\n",
    "train = sorted([i for i in os.listdir(train_data_dir) if os.path.isdir(os.path.join(os.getcwd(),os.path.join(train_data_dir,i)))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = set(val).intersection(set(train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move2():\n",
    "    for i in os.listdir(validation_data_dir):\n",
    "        if i not in to_keep:\n",
    "            q=os.path.join(validation_data_dir, i)\n",
    "            if os.path.isdir(q):\n",
    "                shutil.rmtree(q)\n",
    "    print(\"------\")\n",
    "    for i in os.listdir(train_data_dir):\n",
    "        if i not in to_keep:\n",
    "            q=os.path.join(train_data_dir, i)\n",
    "            if os.path.isdir(q):\n",
    "                shutil.rmtree(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'data/sc5'\n",
    "validation_data_dir = 'data/sc5-test'\n",
    "#number of training images\n",
    "nb_train_samples = 0\n",
    "for root, dirs, files in os.walk(train_data_dir):\n",
    "    nb_train_samples += len([i for i in files if i.endswith('.jpg')])\n",
    "\n",
    "#number of images used for testing (validation)\n",
    "nb_validation_samples = 0\n",
    "for root, dirs, files in os.walk(validation_data_dir):\n",
    "    nb_validation_samples += len([i for i in files if i.endswith('.jpg')])\n",
    "print(\"Traning: {}\\nTesting: {}\".format(nb_train_samples, nb_validation_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN MODEL\n",
    "def VGCC18(n_classes, img_width, img_height): #n--numebr of classes\n",
    "\tif K.image_data_format() == 'channels_first':\n",
    "\t\tinput_shape = (3, img_width, img_height)\n",
    "\telse:\n",
    "\t\tinput_shape = (img_width, img_height, 3)\n",
    "\tprint(input_shape)\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\tmodel.add(Conv2D(32, (3, 3)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\tmodel.add(Conv2D(64, (3, 3)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(64))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(n_classes)) #18 classes\n",
    "\tmodel.add(Activation('sigmoid'))\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of our generated images\n",
    "img_width, img_height = 240, 800\n",
    "\n",
    "model = VGCC18(n_classes = len(to_keep),\n",
    "              img_width = 240,\n",
    "              img_height = 800)\n",
    "\n",
    "#tracking our model\n",
    "csv_logger = CSVLogger('training.log')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 200\n",
    "\n",
    "##Data augmentation##\n",
    "#for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range = 30,\n",
    "    rescale=1. / 255,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "#for testing\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "#further augmentation of our data\n",
    "#training\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode = 'categorical')\n",
    "#testing\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode = 'categorical')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size,\n",
    "\tcallbacks=[csv_logger], #logging our progress\n",
    "\tverbose = 1)\n",
    "\n",
    "try:\n",
    "\tscores = model.evaluate_generator(validation_generator, nb_validation_samples // batch_size, pickle_safe = False)\n",
    "\tpredict = model.predict_generator(validation_generator, nb_validation_samples // batch_size, verbose=1)\n",
    "\tsavetxt('scores.txt', scores)\n",
    "\tsavetxt('predictions.txt', predict)\n",
    "except BaseException as error:\n",
    "    print('An exception occurred: {}'.format(error))\n",
    "\n",
    "model.save_weights('my_model_weights_2.h5') #saving weights for further analysis\n",
    "model.save('my_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
